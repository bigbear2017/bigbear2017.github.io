<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 机器学习 | To Be Your Salt]]></title>
  <link href="http://bigbear2017.github.io/blog/categories/ji-qi-xue-xi/atom.xml" rel="self"/>
  <link href="http://bigbear2017.github.io/"/>
  <updated>2016-06-08T23:01:08+08:00</updated>
  <id>http://bigbear2017.github.io/</id>
  <author>
    <name><![CDATA[Cao Nannan]]></name>
    <email><![CDATA[sei_michael@126.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[OWL-QN算法介绍]]></title>
    <link href="http://bigbear2017.github.io/blog/2016/06/07/owl-qnsuan-fa-jie-shao/"/>
    <updated>2016-06-07T00:08:56+08:00</updated>
    <id>http://bigbear2017.github.io/blog/2016/06/07/owl-qnsuan-fa-jie-shao</id>
    <content type="html"><![CDATA[<h5>版权声明：本文所有内容都是原创，如有转载请注明出处，谢谢。</h5>

<h3>算法引言</h3>

<p>我们之前介绍了Logistic Regression。通常情况下，对LR进行正则化，我们都会使用L2 norm，因为求导比较简单。但是L1 norm 相对于L2 norm有2个好处：</p>

<ol>
<li>当很多的特征都不相关，我们仍然可以训练出一个好的模型（Ng 2004）</li>
<li>生成的模型，大多数的参数都是0。后面我们会知道这是为什么。</li>
</ol>


<p>第二个条件对很多线上的任务，是一个非常好的属性。因为很多没必要的参数为0，就可以显著的减少线上的计算量。如果是使用L2 norm，大多数的参数都会是接近于0，比如0.004，虽然很小，但是还是要计算这一位的值。</p>

<p>假设我们的参数为$x \in R^p$, 如果我们了解L1 Norm，我们就知道我们需要minimize 的函数如下:</p>

<p>$$f(x) = \ell(x) + r(x) =  \ell(x) + C \sum_{i=1}^{p} |x_i|$$
其中$\ell(x)$是negative loglikelihood。很明显，这个函数不可导。我们连一阶导数都没办法求出来，更别提二阶导数了。所以，我们是不可能用剃度下降或者牛顿法等等。</p>

<h3>算法思想</h3>

<p>作者是怎么想出来OWL-QN(orthant-wise Limited-memory Quasi-Newton)呢？主要的想法是这样的：</p>

<p><em>如果限制到某一个单一象限，上面的$f(x)$就是可导的。并且呢，他还是与 $r(x)$是线性相关的。因此, $r(x)$的那部分，在二阶导数的时候就为0。这也就是说，f(x)在二阶导数上，只与$\ell(x)$有关，与$r(x)$无关。</em></p>

<p>这样的话，于是我们就有了这样的想法：</p>

<ul>
<li>构造一个接近的二次函数，这个接近的意思是，在某个象限内和原函数是一致的</li>
<li>对构造的二次函数，利用Hessian Matrix，找到下降的梯度方向</li>
<li>根据梯度方向，进行受限制的线性搜索，受限制的线性搜索的意思是与原来的$x$的象限一致</li>
</ul>


<p>首先，我们可以构造下面一个函数:
$$ f(x) = \ell(x) + C\xi ^T x $$
其中$\xi_i$和$x_i$同号，并且$\xi_i \in { 1, 0, -1 }$。这样，这个方程和原来的方程的值，在不变象限的情况下，值是一样的。并且关键的是，现在这个方程，是可导的，可导的。这太美了，可以求极值了。我们就利用这个方程，找到梯度下降的方向。然后进行受限制的线性搜索。</p>

<h4>确定导数</h4>

<p>在确定梯度方向的时候，我们还是要确定函数的一阶导数。对于$x_i \ne 0$，这个很好办，方程是可导，我们可以得到$\partial_i f(x) = \frac{\partial }{\partial x_i}\ell + C\sigma(x_i)$。但是对于$x_i = 0$的情况，就比较麻烦，因为这个时候，方程是不可导的。方程的偏导数定义如下:
$$ \partial_i^{\pm} f(x) = \frac{\partial}{\partial x_i} \ell \pm C $$
根据上面的定义，右导数一定比左导数大。如果左偏导和右偏导符号一样，那么我们就选择那个比较小的。如果符号不同，那么就为0。定义如下：
$$\partial_i f(x)  = \begin{cases}
\partial_i^{-} f(x), if \partial^{-}f(x) \gt 0 \\\
\partial_i^{+} f(x), if \partial^{+}f(x) \lt 0 \\\
0, \text{otherwise}
\end{cases}$$</p>

<h4>确定$\zeta$</h4>

<p>首先，我们知道$\zeta$和$x$是同符号的。所以对于$x_i \ne 0$的时候，我们知道是和$x_i$一样的符号。但是$x_i = 0$的时候，我们怎么办呢？想到line search是加上负梯度方向来的，我们就取负梯度的方向。所以，$\zeta$定义如下：
$$\zeta_i^{k} = \begin{cases}
\sigma(x^k_i), if x_i^k \ne 0 \\\
\sigma(- \partial_i f(x)), if x_i^k = 0
\end{cases} $$</p>

<h4>受限制的线性搜索</h4>

<p>我们需要保证line search 是在同一个象限的。也就是说，如果是在同一象限，我们就保留，如果不在同一象限就取$0$。定义如下:</p>

<p>$$ x^{k+1} = \pi( x^k + \alpha p^k, \zeta^k) $$</p>

<h3>算法合并</h3>

<blockquote><p>Algorithm OWL-QN
chose initial point $x<sup>0</sup>$</p>

<p>S = {}, Y = {}</p>

<p>for k = 0 to maxIters do</p>

<blockquote><p>Compute $v^k = - \partial f(x)$</p>

<p>Compute $d^k = H_k v^k$ using S and Y</p>

<p>$p^k = \pi ( d^k, v^k )$</p>

<p>Find $x^{k+1}$ with constraned line search</p>

<p>If termination satisfied return $x^{k+1}$ end if</p>

<p>update S with $s^k = x^{k+1} - x^{k}$</p>

<p>update Y with $y^k = \partial \ell(x^{k+1}) - \partial \ell(x^k)$</p></blockquote>

<p>end for</p></blockquote>

<p>这里有一步，我们没有进行解释，就是$p^k = \pi ( d^k, v^k )$保留了吧，这个文章里面有注释。</p>

<h3>算法讨论</h3>

<p>我觉得理解这个算法，主要是抓住一个点。就是$|x|$这个函数，在一个象限里面是可导的，连续的。只有在$0$点，那个位置才是不可导的。所以，我们线性搜索的时候，并不是直接根据梯度，而是受限制的梯度下降。如下图，我们不是要跨象限，而是只到$0$。这样，我们大多数的参数也都变成了0。
<img src="http://7xv0xu.com1.z0.glb.clouddn.com/absx.jpg" alt="abs" /></p>

<h3>参考论文:</h3>

<p><a href="http://www.machinelearning.org/proceedings/icml2007/papers/449.pdf">Scalable Training of L1-Regularized Log-Linear Models</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[GradientBoosting算法介绍]]></title>
    <link href="http://bigbear2017.github.io/blog/2015/11/24/gradientboostingsuan-fa-jie-shao/"/>
    <updated>2015-11-24T23:45:10+08:00</updated>
    <id>http://bigbear2017.github.io/blog/2015/11/24/gradientboostingsuan-fa-jie-shao</id>
    <content type="html"><![CDATA[<h5>版权声明：本文所有内容都是原创，如有转载请注明出处，谢谢。</h5>

<h3>算法介绍</h3>

<p>由AdaBoosting算法，我们知道了什么是Boosting算法，算法大概的结构如下:</p>

<p>$$ G(x) = \sum_{i = 1}^{M} \alpha_i g_i( x ) $$</p>

<p>其中$g_i(x)$是弱分类器，$\alpha_i$是每个分类器的权重。在每一步中，AdaBoosting利用那些被分错类的点，然后增加权重，重新训练一个新的分类器，并且计算分类器的权重。
那什么是Gradient Boosting呢？类似于AdaBoosting, Gradient Boosting也是一种Boosting的算法，结构和上面一样。只是Gradient Boosting是利用Gradient来重新训练一个新的分类器，然后计算权重。</p>

<h3>算法理解</h3>

<h5>1. 简单的Boosting</h5>

<p>如果我们只有一个简单的分类器$g(x)$，不用AdaBoosting，如何进行Boosting呢？
可能最简单的是用Residual来进行训练，过程如下:</p>

<blockquote><p>for j = 1 to M</p>

<blockquote><p>$ r_{ji} = ( y_i - G_{j-1}(x_i) ) $ //r_j should be a vector, size of N</p>

<p>fit $g_j(x)$ to $r_j$</p>

<p>$\alpha_j = \arg \min_{\alpha} \sum_{i = 1}^n L( y_i, G_{j-1} ( x_i ) + \alpha * g_j(x_i) )  $</p>

<p>$G_j(x) = G_{j-1}(x) + \alpha_j g_j(x) $</p></blockquote></blockquote>

<h5>2. 使用Gradient</h5>

<p>上面的每一步，我们使用了一个Residual $(y_i - G_{j-1}(x_i) )$ 来重新训练模型。这个表面上看是挺好的，每一次我们都在逼近$y$。但实际上，我们真的在减少Loss吗？假设我们使用Squared Error作为Loss. 那么: $L=  \sum_{i=1}^N ( y_i - \sum_{j=1}^M g_j(x_i) )^2$ 。这个是不是让我们想到Least Squared Regression呢？里面的$\beta$是如何更新的呢？因为是minimize loss，所以，我们是每次加上负梯度，更新如下:
$\beta_{j+1} = \beta_{j} - \frac{\partial L}{\partial \beta }$</p>

<p>看到这个，是不是我们好像似乎明白了什么。假如，我们把每一个$g_i(x)$都看成变量，如果我们想$G(x)$更接近$y$，那我们应该如何更新呢？
$G(x) = G (x) - \frac{\partial L}{\partial G(x)}$
从这个角度，我们再来理解$y_i - G_j(x_i)$的话，就可以知道它其实就是$L = (y - G(x))^2$的负梯度($-\frac{\partial L} {\partial G(x)} = - ( y - G(x) ) * -1 = y - G(x) $).</p>

<h4>其他梯度</h4>

<h5>1. Absolute Loss</h5>

<p>Absolute loss的定义如下:</p>

<p>$$ L(y, G) = |y - G|$$</p>

<p>梯度如下:
$$ \frac{\partial L}{\partial G} =
\begin{cases}
y - G(x) &amp; if y \ge G(x) \\\
G(x) - y &amp; otherwise
\end{cases} $$</p>

<h5>2. Huber Loss</h5>

<p>$$ L_\delta(y, f(x)) =
\begin{cases}
 \frac{1}{2}(y - f(x))^2                   &amp; \textrm{for} |y - f(x)| \le \delta, \\\
 \delta\, |y - f(x)| - \frac{1}{2}\delta^2 &amp; \textrm{otherwise.}
\end{cases} $$</p>

<p>所以
$$
\frac{\partial L_\delta(y, G(x))} {\partial G} = \begin{cases}
y - G(x)                 &amp; \textrm{for} |y - G(x)| \le \delta, \\\
 \delta sign( y - f(x) )  &amp; \textrm{otherwise.}
\end{cases} $$</p>

<h4>算法过程</h4>

<blockquote><p>Input: training set ${(x_i, y_i)_{i=1}^n}$</p>

<p>初始化learner function $G_0$为常数</p>

<p>for j = 1 to M</p>

<blockquote><p>$ r_{ji} = -\frac{\partial L} {\partial G_{j-1}(x_i)} $ //$r_j$ should be a vector, size of N</p>

<p>fit $g_j(x)$ to $r_j$</p>

<p>$\alpha_j = \arg \min_{\alpha} \sum_{i = 1}^n L( y_i, G_{j-1} ( x_i ) + \alpha * g_j(x_i) )  $</p>

<p>$G_j(x) = G_{j-1}(x) + \alpha_j g_j(x) $</p></blockquote></blockquote>

<p>初始化learner function $F_0$为常数
计算negative gradient
以negative gradient为目标进行训练得到一个简单的learner
找到最优的常数得到新的更强的learner</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AdaBoosting算法介绍]]></title>
    <link href="http://bigbear2017.github.io/blog/2015/09/27/adaboostingsuan-fa-jie-shao/"/>
    <updated>2015-09-27T21:41:04+08:00</updated>
    <id>http://bigbear2017.github.io/blog/2015/09/27/adaboostingsuan-fa-jie-shao</id>
    <content type="html"><![CDATA[<h5>版权声明：本文所有内容都是原创，如有转载请注明出处，谢谢。</h5>

<p>Boosting 是一种很有意思的算法。在没有SVM之前，今天就让我们来一同回顾一下这个经典的算法吧。</p>

<h2>1. 模型定义</h2>

<p>假设模型的输入为$X \in R^p$，输出为$ Y \in (-1, 1)$，输入和输出都有N个点。我们手上呢，有一个很简单的classfier，$G(x)$，他实在不怎么样，可能就比随机猜要好一点点。我们如何利用这个简单的分类器，对数据进行很好的分类呢？AdaBoosting就提出一种很好的办法: 将弱的分类器组合起来，然后我们形成一个强的分类器。这个想法很好，但是我们真的可以把分类器组合起来吗？首先怎么把分类器组合起来呢？直接用余数来训练吗？这样组合起来，分类器变的更糟糕，怎么办？AdaBoosting巧妙地利用了每一个分类器的优点，并且组合了起来。结果也是相当地惊人，在它刚刚被提出来的时候，几乎是当时最好的算法。首先，组合分类器的定义如下:</p>

<p>$$ G(x) = sign ( \sum_{i =1 }^{M} \alpha_m G_m(x)) $$</p>

<p>那如何得到每一个弱分类器的权重呢？AdaBoosting 是利用了每个分类器的错误率来进行组合的，每一次用$G(x)$来分类的错误率就定义如下:</p>

<p>$$ E = \frac{1}{N} \sum_{i=1}^{N} I(y_i \ne G(x_i)$$</p>

<h2>2.模型训练</h2>

<p>Algorithm AdaBoost</p>

<blockquote><ol>
<li>Initialize  $ \omega_i = \frac{1}{N} $,  i = 1, 2, &hellip; N</li>
<li>For m = 1 to M:

<blockquote><p>Fit a classifier G(x) to training data using weights $\omega_i$</p>

<p>Compute
$$ err_m = \frac{\sum_{i=1}^{N} \omega_m I( y_i \ne G_m(x))} {\sum_{i = 1}^{N} \omega_i}  $$
Compute $ \alpha_m = \log(\frac{( 1 - err_m)} {err_m} ) $
Update $\omega_i  = \omega_i \exp(\alpha_m I( y_i \ne G_m(x_i) )$</p></blockquote></li>
<li>Output  $ G(x) = sign[ \sum_{m=1}^{M} \alpha_m G_m(x) ] $</li>
</ol>
</blockquote>

<h2>3. 算法解读</h2>

<ol>
<li>为什么 $\alpha_m$定义是 $\log(\frac{( 1 - err_m)} {err_m} )$ ?</li>
</ol>


<p>首先$err_m$的取值范围是$(0, 1)$。如果分类器$G_m(x)$的错误率越高，那么$err_m$就越接近于1, 否则就越接近于$0$。而根据常识来说，如果一个分类器很差劲，错误率越高呢，我们就希望他的权重就越低，越接近于0。而这样的话，就让我们想到了一个很常见的函数sigmod fuction。就让我们来证明这个来历吧。</p>

<p>$$ \begin{matrix}
err_m =  \frac{1}{1 + \exp^{\alpha}} \\
=> 1 + \exp^{\alpha} = \frac{1}{err_m} \\
=> \exp^{\alpha} = \frac{1}{err_m} - 1 \\
=> \alpha = \log(\frac{( 1 - err_m)} {err_m} )
\end{matrix} $$</p>

<p>上面并不是logistic function(lf)，而是一个按照y轴对称的lf，因为如果直接用lf的话，err越大，权重也会越大了。</p>

<ol>
<li>为什么每次要更新$\omega_i$ ?
对于 $\omega_i$ 的更新，我们可以进行这样的解读:

<blockquote><p>if $y_i == G(x_i)$ $\omega_i == \omega_i$</p>

<p>else $\omega_i = \omega_i * \frac{1- err_m}{err_m}$</p></blockquote></li>
</ol>


<p>对于 $\frac{1- err_m}{err_m}$，我们知道$err_m$越大，值越小。也就是说，错误率越高，我们的就权重越低。这是可以理解的，如果$err_m$很大，说明分类器不好。被这样一个分类器给分错了，那我们可能觉得没关系。但是如果$err_m$很小，说明分类器很好，被一个很好的分类器分错了，说明这个点，我们希望在下次的时候，可以被其他的分类器补充。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AUC-COPC指标介绍]]></title>
    <link href="http://bigbear2017.github.io/blog/2015/07/24/auc-copczhi-biao-jie-shao/"/>
    <updated>2015-07-24T20:56:45+08:00</updated>
    <id>http://bigbear2017.github.io/blog/2015/07/24/auc-copczhi-biao-jie-shao</id>
    <content type="html"><![CDATA[<h5>版权声明：本文所有内容都是原创，如有转载请注明出处，谢谢。</h5>

<h3>AUC</h3>

<p>AUC 的全称是Area Under Curve，简单的来说就是<strong><em>计算某条线以下的面积</em></strong>。说起AUC，就不得不说ROC（Receiver Operating Characteristic）曲线。计算ROC曲线，我们需要知道两个名词：true positive rate 和 false positive rate。这两个值的计算很简单，比如有10个样本，有7个是正例，3个是负例。那当我们假设都是positive的时候，tpr是0.7，fpr是0.3。那如何计算AUC呢？</p>

<ol>
<li><p>将所有的预估值从大到小进行排序</p></li>
<li><p>将所有的值划分成n个等分</p></li>
<li><p>假设当前的等分点是p, 所有大于p的都看成正例，所有小于p的都看成负例。按照这个规则，计算每个等分之前的tpr和fpr</p></li>
<li><p>把每个等分当成是平的，积分算面积</p></li>
</ol>


<h4>举个例子</h4>

<p>假如有20个样本, 把样本的预测值从大到小排序，如下图:</p>

<p><img src="http://7xv0xu.com1.z0.glb.clouddn.com/auc1.jpg" alt="sortP" /></p>

<p>那么我们把上面划分成20等分，计算每一个等分上的TPR和FPR，然后画出下面的图:</p>

<p><img src="http://7xv0xu.com1.z0.glb.clouddn.com/auc2.jpg" alt="imageP" /></p>

<p>这样我们就可以计算 AUC = 0.1 x 0.2 + 0.2 x 0.5 + 0.1 x 0.6 + 0.1 x 0.7 + 0.3 x 0.8 + 0.1 * 0.9 + 0.1 * 1 = 0.02 + 0.1 + 0.06 + 0.07 + 0.24 + 0.09 + 0.1 = 0.68</p>

<h4>AUC 的意义</h4>

<p>​从上面的图来看，如果auc大，就表示说，我们能很容易的区分正例和负例。但是对于正例和负例，具体的值，我们是不能够确定的。只能够差不多知道，它是正例，另外是负例。所以AUC，比较适合在分类的场景中，而不适合在回归的场景中。但这不表示AUC在回归的场景中，就不重要。在回归的场景中，我们仍然能够部分地看出模型的状况。</p>

<h3>COPC</h3>

<p>这个主要是用来衡量模型是否收敛，就不多说了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[NeronNetwork算法介绍]]></title>
    <link href="http://bigbear2017.github.io/blog/2015/06/22/neronnetworksuan-fa-jie-shao/"/>
    <updated>2015-06-22T20:05:00+08:00</updated>
    <id>http://bigbear2017.github.io/blog/2015/06/22/neronnetworksuan-fa-jie-shao</id>
    <content type="html"><![CDATA[<h5>版权声明：本文所有内容都是原创，如有转载请注明出处，谢谢。</h5>

<p>最近深度学习实在太火了，火到各个公司都在搞实验室。但是深度学习的基础，还是从neron network，BP，这样的算法开始。
就简单回顾一下最简单的NN吧。</p>

<h3>1. 算法介绍</h3>

<p>我们假设只有一层的隐藏层，并且大小为M，输入$X \in R^p$，输出$Y \in R^K$，输出$Y$属于$K$ classes。所以，我们可以得到下面的定义:</p>

<p>$$ \begin{matrix}
D_m = \rho ( \alpha_m0 + \alpha_m^T X ) , m = 1, 2, &hellip; M \\
T_k = \beta_k0 + \beta_k^T D, k = 1, 2, &hellip; K \\
f_k(X) = g_k( T ) , k = 1,2, &hellip; K
\end{matrix}$$</p>

<p>其中$D = (D_1, D_2, &hellip; , D_M)$, $\rho = \frac{1}{ 1 + \exp^{(-v)} }$是sigmod function, $g_k$可以是identity function，或者是softmax function $\frac{exp^{T_k}}{\sum_{l = 1}^{K} exp^{T_l}}$.</p>

<h3>2. 求解</h3>

<p>训练采用的back propagation的方式，就是先利用参数计算结果，然后根据结果计算梯度，根据梯度再优化参数。
根据上面的定义，我们可以得到loss function $R(\alpha, \beta)$如下:</p>

<p>$$
R(\alpha, \beta) = \sum_{k = 1}^K \sum_{n = 1}^N ( y_{ik} - f_k( x_i ) ) ^2
$$</p>

<p>其中$N$是样本数, $K$是样本的class的数目. 所以对$\alpha, \beta$分别求偏导，我们可以得到:</p>

<p>$$\begin{matrix}
\frac{\partial R_i}{\partial \beta_{km} } = -2(y_{ik} - f_k( x_i ) ) g^{\prime}(T_k) D_{mi}   \\
\frac{\partial R_i}{\partial \alpha_{mp}} =  -\sum_{k=1}^{K}2(y_{ik} - f_k( x_i ) ) g^{\prime}(T_k) \beta_{k}\rho^{\prime}(\alpha_m^T x_i) x_{ip}
\end{matrix}
$$</p>

<p>根据上面的式子，我们就可以利用gradient descent的方式，来训练模型了.</p>

<p>$$ \begin{matrix}
\beta^{r+1}_{km} = \beta^{r}_{km}  - \gamma_r \frac{\partial R_i}{\partial \beta_{km} } \\
\alpha^{r+1}_{mp} = \alpha^{r}_{mp}  - \gamma_r \frac{\partial R_i}{\partial \beta_{mp} }
\end{matrix}$$</p>

<h3>3. 向量化</h3>

<p>上面的式子，实在看着太繁琐了，我们还是对其进行向量化，可能看着更简单，实现也更方便一些.
待续</p>

<h3>4. 注意点</h3>

<h4>1. 输入的起始点，不可以全部是零。因为全部是零的话，就永远全部是零，无法训练。也不可以过大，结果会不太好。最好的是随机靠近0的数。</h4>

<h4>2. 隐藏层多一点比较好，可以表达的非线性的能力就越强一点</h4>

<h4>3. 加正则防止过拟合。</h4>
]]></content>
  </entry>
  
</feed>
