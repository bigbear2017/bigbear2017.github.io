<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 深度学习 | To Be Your Salt]]></title>
  <link href="http://bigbear2017.github.io/blog/categories/shen-du-xue-xi/atom.xml" rel="self"/>
  <link href="http://bigbear2017.github.io/"/>
  <updated>2016-12-23T00:20:34+08:00</updated>
  <id>http://bigbear2017.github.io/</id>
  <author>
    <name><![CDATA[Cao Nannan]]></name>
    <email><![CDATA[sei_michael@126.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Word2Vec算法介绍一: A Neural Probabilistic Language Model]]></title>
    <link href="http://bigbear2017.github.io/blog/2016/11/22/word2vecsuan-fa-jie-shao/"/>
    <updated>2016-11-22T08:00:10+08:00</updated>
    <id>http://bigbear2017.github.io/blog/2016/11/22/word2vecsuan-fa-jie-shao</id>
    <content type="html"><![CDATA[<h5>版权声明：本文所有内容都是原创，如有转载请注明出处，谢谢。</h5>

<h3>引言</h3>

<p>这篇文章基本上是word2vec的开篇之作，后来的工作也都是在这篇文章的基础上，进行的优化。之所以要做word2vec，目的也是比较明显的。
在没有word2vec之前，如果我们想计算两个句子的相似性，就只能用ngram这种方式来计算相似性。但是这种方式的缺点是，由于词汇量都很大，导致生成的数据向量的维度都很大，并且很稀疏。另外，无法考虑两个词的语义相似性。比如，一只猫正在卧室里走。通过对语料的训练，我们应该可以得到，相似的语句像一只狗正在卧室里走。Word2Vec利用统计语言模型，对上面的问题有了一个初步的解决方法。</p>

<h3>算法结构</h3>

<p>word2vec基本上可以分为这样几步：</p>

<ol>
<li>对于词典中的每一个词，都关联一个特征向量</li>
<li>使用特征向量来表示词组序列的概率函数</li>
<li>利用词组数据来学习 特征向量和概率函数的参数</li>
</ol>


<p>第一步很简单，对于每一个词，我们随机初始化一个特征向量。第二步，这个就是神经网络的设计了。具体的设计，会在下面说明。
第三步，就是通过数据训练神经网络，得到一个合理的特征向量和神经网络的参数。这个就比较简单了。先是用FeedForward计算输出值，再用BackForward 求导计算。</p>

<p>通过上面的方式，我们可以得到两个部分，一个是被压缩的特征向量。另外一个是训练好的神经网络。我们经常使用的是特征向量，因为通过它，我们会发现一些非常有趣的事情。比如，向量(猫) 和 向量(狗)会比较接近。甚至 向量(皇后) + 向量(男人) 和向量(皇帝)很接近。通过这种把词语转换成向量的方式，我们就可以做很多事情。比如聚类，分类，甚至是文档的匹配等等。</p>

<h3>具体的过程</h3>

<p>训练的过程是为了最大化log-likelihood，定义如下：</p>

<p>$$ L = \frac{1}{T} \sum_t \log f(w_t, w_{t-1}, &hellip;, w_{t-n+1}; \theta ) + R(\theta) $$</p>

<p>论文中给出的具体计算过程如下图：</p>

<p><img src="http://www.bigbear2017.com/images/word2vec-network.png" height="500" width="500" alt="word2vec" /></p>

<p>从上面的图我们可以知道：</p>

<p>$$ f(x) = b + Wx + U tanh(d + Hx)$$</p>

<p>where $tanh(x) = \frac{e^x - e^{-x}}{ e^x + e^{-x} }$ and $\frac{d}{dx} tanh = 1 - tanh^2 x$
神经网络的输入是$w_t, w_{t-1}, &hellip;, w_{t-n +1}$，通过mapping matrix C，我们得到每个词相应的vector $C(w_t )$。每一次训练的时候，把输入$w_{t-1}, &hellip; , w_{t-n+1}$，合并成一个vector，得到我们输入:</p>

<p>$$ x = ( C(w_{t-1}), C(w_{t-2}), &hellip;, C(w_{t-n+1})) $$</p>

<p>而我们输出层$y_i$是由$w_t$映射到 one-hot encoder得到。但是我们的神经网络的结果可能会大于1。所以作者就在最后一层增加了一个soft max.</p>

<p>$$ P( w_t | w_{t-1}, &hellip;, w_{t-n +1} )  = \frac{\exp^{y_{w_t}}}{\sum_{i} \exp^{y_i}} $$</p>

<p>这样，我们就可以训练整个神经网络了。</p>

<h4>计算过程：</h4>

<p>主要的forward过程比较简单，可以很容易完成。首先我们可以把$f(x)$ 分成两步：</p>

<p>$$a = d + Hx;$$</p>

<p>$$f(x) = b + Wx + U tanh(a)$$</p>

<p>back propagation需要计算偏导数会有点麻烦，具体如下：</p>

<p>$$ \frac{\partial f(x) }{\partial b} = 1$$</p>

<p>$$ \frac{\partial f(x)}{\partial W} = x$$</p>

<p>$$ \frac{\partial f(x)}{\partial U} = a$$</p>

<p>$$ \frac{\partial f(x)}{\partial d} =  \frac{\partial f(x)}{\partial a}  \frac{\partial a}{\partial d} = U ( 1 - a^2) * 1$$</p>

<p>$$ \frac{\partial f(x)}{\partial H} =  \frac{\partial f(x)}{\partial a}  \frac{\partial a}{\partial H} = U ( 1 - a^2) * x $$</p>

<h4>一个问题：如何训练C</h4>

<p> 我们知道神经网络可以训练参数，这个很容易理解。但是C作为输入的一部分，如何进行训练呢？其实，应该说word2vec有两层的隐含层。C也是通过训练得到。每一次输入的时候，我们可以把C看成是$C = X$，这样，我们就可以对$C$进行求偏导，具体如下：</p>

<p>$$ \frac{\partial f(x)}{\partial C} =  \frac{\partial f(x)}{\partial a}  \frac{\partial a}{\partial X}  \frac{\partial X}{\partial C} = U ( 1 - a^2) * H + W $$</p>

<h3>Word2Vec的意义</h3>

<p>Word2Vec使我们很轻松的将一个词，转化成一个vector，类似于AutoEncoder，Word2Vec使我们可以很容易提取一些相对准确高维的特征。我个人觉得这也是它不同于其他语言模型的地方。像LDA，也可以提取一些高维的特征，但是效果明显不如Word2Vec。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用MxNet进行图片的二分类]]></title>
    <link href="http://bigbear2017.github.io/blog/2016/06/15/shi-yong-mxnetjin-xing-tu-pian-de-er-fen-lei/"/>
    <updated>2016-06-15T10:59:13+08:00</updated>
    <id>http://bigbear2017.github.io/blog/2016/06/15/shi-yong-mxnetjin-xing-tu-pian-de-er-fen-lei</id>
    <content type="html"><![CDATA[<h5>版权声明：本文所有内容都是原创，如有转载请注明出处，谢谢。</h5>

<h4>1. 引言</h4>

<p>偶尔遇到了这样一个问题，如何进行图片分类。最近deep learning很火，我们就试着用了一把，效果不错。Mxnet里面有很多训练的例子，可是如何拿训练好的模型去预测，如何生成训练数据，都没有实际的例子。这个就做一个实际的例子，来看看mxnet如何在我们工作中被使用。这个应用可以用来分别图片中是否是人，是否是狗，是否是猫。。。</p>

<h4>2. 生成训练Rec文件</h4>

<pre><code>python ../tools/make_list.py --train_ratio 0.9 --recursive true ../data/2016-06-12/ samples0612
python ../tools/im2rec.py --train_ratio 0.9 --recursive true --resize 224 samples0612_train ../data/2016-06-12/
</code></pre>

<h4>3. 利用ImageClassification 进行训练</h4>

<p>这里我们使用了inception-bn的网络。相对于lenet, inception的深度更深，参数更复杂，训练和预测也更慢一点，但效果更好。相对于inception，incetion-bn对参数做了batch normalization，更加容易收敛，效果也更好。
<code>
python2.7 ../train_imagenet.py --network inception-bn --data-dir ./  --model-prefix inception --gpus 0 --num-classes 2 --num-epochs 20 --load-epoch 3 --train-dataset samples0612_train.rec --val-dataset samples0612_val.rec --batch-size 70 --log-dir ./ --log-file train.log
</code></p>

<h4>4. 生成测试Rec文件</h4>

<pre><code>python2.7 ${CURR_DIR}/tools/make_list.py ${IMAGE_DATA} ${CURR_DIR}/Images
python2.7 ${CURR_DIR}/tools/im2rec.py --resize 224 ${CURR_DIR}/Images ${IMAGE_DATA}
</code></pre>

<h4>5. 利用训练好的模型进行预测</h4>

<pre><code>data = mx.io.ImageRecordIter( path_imglst = 'Images.lst',  path_imgrec = 'Images.rec', ctx = mx.gpu(0), data_shape = (3,224,224), batch_size = 50, mean_r  = 123.68, mean_g      = 116.779, mean_b      = 103.939 )
model = mx.model.FeedForward.load('inception-0', 3, data_shape = (3,224,224), batch_size = 50, ctx= mx.gpu(0))
y = model.predict( data )
## y = 1 - y
pkl.dump(y, open( 'y-labels', 'w'))
</code></pre>

<h4>6. 经验之谈</h4>

<ol>
<li>图片分类对训练数据很敏感。如果训练数据都是错误的，那么预测就根本不可能正确了。所以训练数据需要非常认真的检查</li>
<li>训练数据不仅仅需要正确，也需要全面。对于图片方面的训练，更多的图片就能覆盖更多的方面</li>
<li>训练和预测的时候，参数需要是一样的。其中，我们设置了 mean_r, mean_g, mean_b。</li>
</ol>

]]></content>
  </entry>
  
</feed>
