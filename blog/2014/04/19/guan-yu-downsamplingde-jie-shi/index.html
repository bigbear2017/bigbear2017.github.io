
<!DOCTYPE HTML>
<html>
<head>
	<meta charset="utf-8">
	<title>关于Downsampling的解释 | To Be Your Salt</title>

	<meta name="author" content="Cao Nannan"> 
	
	<meta name="description" content="我是一个基督徒，喜欢机器学习，Linux, 编程方面的知识。目前从事点击率预估， 文字链匹配广告，以及想关的工作。 生活中，我喜欢上帝，喜欢耶稣基督，也喜欢读圣经。"> <meta name="keywords" content="">

	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<link href="/atom.xml" rel="alternate" title="To Be Your Salt" type="application/atom+xml">
	<link rel="canonical" href="">
	<link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
	<link href="/stylesheets/font-awesome.min.css" rel="stylesheet" type="text/css">
	
	<!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
	
</head>



<body>
	<header id="header"><div class="inner">
  <ul class="navigation">
    <li><a href="/"><h1>To Be Your Salt</h1></a></li>
    <li><a href="/" class="is-selected">Blog</a></li>
    <li><a href="http://github.com/bigbear2017" target="blank">Github</a></li>
  </ul>
</div>
</header>

	<div id="content" class="inner"><article class="post">
	<h2 class="title">关于Downsampling的解释</h2>
	<div class="meta">
		<div class="date">








  



<time datetime="2014-04-19T21:18:25+08:00" pubdate data-updated="true">Apr 19th, 2014</time></div>
	</div>
	<div class="entry-content"><h5>版权声明：本文所有内容都是原创，如有转载请注明出处，谢谢。</h5>

<h3>为什么进行DownSampling?</h3>

<p>在很多预测的场景，负例样本过多。比如有超过10亿以上。如果这些样本全部都拿来训练，训练的时间比较长，机器可能会撑不住。这个时候，我们不会使用全部的负例，而是使用1/100甚至1/1000的样本去训练。这样训练的结果就不是原本的概率，而是在down sampling之后的概率。这样就我们需要对两个概率进行矫正。</p>

<h3>如何矫正?</h3>

<p>既然使用现在的模型得到的概率, 不是在原来样本上得到的概率，那如何进行矫正呢？假设原本的概率为$P_1$, downsampling之后的概率为$P_2$，正例和负例分别为$P, N$，down sampling使用$1/t$的随机概率进行down sampling. 所以，我们可以得到：</p>

<p>$$ \begin{matrix}
P_1 = \frac{P}{P+N} \\
P_2 = \frac{P}{P+ N/t}
\end{matrix}$$</p>

<p>由上面的式子，我们可以得到:</p>

<p>$$ \begin{matrix}
P = \frac{P_1} {1- P_1} N \\
P = \frac{P_2}{1- P_2} \frac{N}{t}
\end{matrix}$$</p>

<p>所以，我们可以得到:</p>

<p>$$ P_2 = \frac{P_1 t }{P_1 t + 1 - P_1}$$</p>

<p>$$ P_1= \frac{P_2}{t - P_2 t + P_2}$$</p>

<p>假如我们使用的logistic regression，那么: $P_2 = \frac{1}{1 + \exp^{-wx}}$，代入得到:</p>

<p>$$ P_1 = \frac{1}{(1+\exp^{-wx}) t - t + 1}$$</p>

<p>$$ P_1 = \frac{1}{\exp^{-wx}t  + 1}$$</p>

<p>$$ P_1 = \frac{1}{\exp^{-wx+\ln{t}}  + 1}$$</p>

<p>这样，在我们训练的模型，之后再加一个bias，我们就得到了，一个样本在未downsampling之前的同等概率。</p>

<h4>其他应用</h4>

<p>OverSampling方面其实也是类似。这方面还要再思考一下。</p>
</div>


<div class="sharing">
  
  
  
</div>
</article>
</div>
	<footer id="footer" class="inner"><script type="text/x-mathjax-config"> 
MathJax.Hub.Config({
	tex2jax: {
		inlineMath: [ ['$','$'] ],
		displayMath: [ ['$$','$$'] ],
	},
	processEscapes: true
});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>
<div class="aboutme">
<hr>
  <div class="profile">
    <a href="http://twitter.com/"><img class="icon" src=""></a>

    <h3>Cao Nannan</h3>
    <p><a href="http://twitter.com/">@</a></p>

    <div class="codes">
      <h4>Codes</h4>
      <div class="github"><a href="https://github.com/bigbear2017">github.com/bigbear2017</a></div>
    </div>
  </div>

  <div class="float_clear"></div>

</div>
Copyright &copy; 2016
 Cao Nannan 
<br>
Powered by Octopress.



</footer>
	

</body>
</html>
