
<!DOCTYPE HTML>
<html>
<head>
	<meta charset="utf-8">
	<title>如何使用MapReduce计算文本的tf-idf | To Be Your Salt</title>

	<meta name="author" content="Cao Nannan"> 
	
	<meta name="description" content="我是一个基督徒，喜欢机器学习，Linux, 编程方面的知识。目前从事点击率预估， 文字链匹配广告，以及想关的工作。 生活中，我喜欢上帝，喜欢耶稣基督，也喜欢读圣经。"> <meta name="keywords" content="">

	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<link href="/atom.xml" rel="alternate" title="To Be Your Salt" type="application/atom+xml">
	<link rel="canonical" href="">
	<link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
	<link href="/stylesheets/font-awesome.min.css" rel="stylesheet" type="text/css">
	
	<!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
	
</head>



<body>
	<header id="header"><div class="inner">
  <ul class="navigation">
    <li><a href="/"><h1>To Be Your Salt</h1></a></li>
    <li><a href="/" class="is-selected">Blog</a></li>
    <li><a href="http://github.com/bigbear2017" target="blank">Github</a></li>
  </ul>
</div>
</header>

	<div id="content" class="inner"><article class="post">
	<h2 class="title">如何使用MapReduce计算文本的tf-idf</h2>
	<div class="meta">
		<div class="date">








  



<time datetime="2014-06-13T17:26:18+08:00" pubdate data-updated="true">Jun 13th, 2014</time></div>
	</div>
	<div class="entry-content"><h5>版权声明：本文所有内容都是原创，如有转载请注明出处，谢谢。</h5>

<p>本文介绍如何使用MapReduce进行文本的tf-idf计算。
程序的输入是一个个的文本，类似下面的：</p>

<p>doc1: w1, w2, w3</p>

<p>doc2: w4, w5, w6</p>

<p>输出为一个个的Vector，可以是Sparse的Vector，或者是Dense Vector,
我们就假设使用Sparse的Vector，输出如下：</p>

<p>doc1_id, 1:0.1, 2:0.1, 3:0.03</p>

<p>doc2_id, 4:0.1, 5:0.1, 6:0.01</p>

<h2>如何使用MapReduce进行计算呢？</h2>

<p>对一个单词$w_i$, 在文档$D_j$中，tf-idf的计算公式如下：
$$ tf_idf= \frac{ N(w_i) } { N( D_j ) } * \log \frac{ \vert D \vert } { \vert j: w_i \in D_j \vert + 1 } $$
其中$N(w_i)$ 是$w_i$在$D_j$中的频率，$N(D_j)$是$D_j$中所有词的频率，也就是文本的长度，
$|D|$为所有文本的个数，$| j: w_j \in D_j |$ 为包含$w_i$的文档个数。</p>

<p>统计tf-idf需要两个MapReduce Job，一个job统计每个词的tf-idf，然后将每个文档中的词聚合到一起。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>MapReduce1 Mapper Input:
</span><span class='line'>doc1: w1, w2, w3 
</span><span class='line'>doc2: w4, w5, w6
</span><span class='line'>MapReduce1 Mapper Output:
</span><span class='line'>w1_index: (doc1_id, tf_w1, w1_index)</span></code></pre></td></tr></table></div></figure>


<p>其中 doc1_id根据对文档名字进行hash得到，tf_w1根据doc1中w1出现的次数来计算，
w1_index根据词典计算，context的counter统计文档数量|D|</p>

<p>MapReduce1 Reducer Output:</p>

<p>doc1_id: (w1_index, tf-idf )</p>

<p>tf-idf根据tf, |D|，所有包含w1的文档的个数</p>

<p>MapReduce2 Mapper: Identity Mapper</p>

<p>MapReduce2 Reducer: 根据doc_id，将所有相同文档归并到一起，得到:</p>

<p>doc1_id: w1_index:tf-idf, w2_index:tf-idf</p>

<p>doc2_id: w4_index:tf-idf, w5_index:tf-idf</p>

<p>还有另外一种方法是，先计算每个词的idf，然后再将idf做为distributed cache
分发给每一个mapper，然后得到每个文本的tf-idf.</p>
</div>


<div class="sharing">
  
  
  
</div>
</article>
</div>
	<footer id="footer" class="inner"><script type="text/x-mathjax-config"> 
MathJax.Hub.Config({
	tex2jax: {
		inlineMath: [ ['$','$'] ],
		displayMath: [ ['$$','$$'] ],
	},
	processEscapes: true
});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>
<div class="aboutme">
<hr>
  <div class="profile">
    <a href="http://twitter.com/"><img class="icon" src=""></a>

    <h3>Cao Nannan</h3>
    <p><a href="http://twitter.com/">@</a></p>

    <div class="codes">
      <h4>Codes</h4>
      <div class="github"><a href="https://github.com/bigbear2017">github.com/bigbear2017</a></div>
    </div>
  </div>

  <div class="float_clear"></div>

</div>
Copyright &copy; 2016
 Cao Nannan 
<br>
Powered by Octopress.



</footer>
	

</body>
</html>
