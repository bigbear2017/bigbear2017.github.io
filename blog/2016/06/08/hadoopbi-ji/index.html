
<!DOCTYPE HTML>
<html>
<head>
	<meta charset="utf-8">
	<title>Hadoop笔记 | To Be Your Salt</title>

	<meta name="author" content="Cao Nannan"> 
	
	<meta name="description" content="我是一个基督徒，喜欢机器学习，Linux, 编程方面的知识。目前从事点击率预估， 文字链匹配广告，以及想关的工作。 生活中，我喜欢上帝，喜欢耶稣基督，也喜欢读圣经。"> <meta name="keywords" content="">

	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<link href="/atom.xml" rel="alternate" title="To Be Your Salt" type="application/atom+xml">
	<link rel="canonical" href="">
	<link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
	<link href="/stylesheets/font-awesome.min.css" rel="stylesheet" type="text/css">
	
	<!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
	
</head>



<body>
	<header id="header"><div class="inner">
  <ul class="navigation">
    <li><a href="/"><h1>To Be Your Salt</h1></a></li>
    <li><a href="/" target="blank">Blog</a></li>
    <li><a href="http://github.com/bigbear2017" target="blank">Github</a></li>
    <li><a href="/blog/2014/03/26/zi-wo-jie-shao/" target="blank"> About ME</a></li>
  </ul>
</div>
</header>

	<div id="content" class="inner"><article class="post">
	<h2 class="title">Hadoop笔记</h2>
	<div class="meta">
		<div class="date">








  



<time datetime="2016-06-08T22:52:09+08:00" pubdate data-updated="true">Jun 8th, 2016</time></div>
	</div>
	<div class="entry-content"><h5>版权声明：本文所有内容都是原创，如有转载请注明出处，谢谢。</h5>

<h3>1. 关于 Hadoop</h3>

<ol>
<li>FileSystem.get( conf ) 会得到缓存的filesystem，因为是缓存的filesystem，这个filesystem是不能关闭的。一旦关闭之后，其他的机器有可能也在读文件，关闭以后其他的机器就不能再读了</li>
<li><p>Hadoop 里面有两个mapreduce的包，一个是hadoop.mapred，一个是hadoop.mapreduce，这两个包不一样的。</p>

<ul>
<li>org.apache.hadoop.mapred 是老的api，org.apache.hadoop.mapreduce是新的api</li>
<li>新的API使用context，并允许用户代码与mapreduce系统进行通信，旧的里面是通过OutputCollector和Reporter两个来通信。但在新的里面，所有的一切都是通过context</li>
</ul>
</li>
<li><p>作业控制通过Job而不是JobClient，作业配置通过Configuration而不是JobConf，老的API通过JobConf对通用的Configuration进行扩展，但在新的里面一切都是Configuration</p></li>
<li><p>Set hadoop heap size before the job running:</p>

<blockquote><pre><code>export HADOOP_HEAPSIZE=4096
</code></pre></blockquote></li>
</ol>


<h3>2. 关于DistributedCache</h3>

<ol>
<li>Use distributed cache:</li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>public void addToDistributedCache(Configuration conf, Path path) throws IOException {
</span><span class='line'> FileSystem fs = FileSystem.get(conf);
</span><span class='line'> FileStatus fileStatus = fs.getFileStatus(path);
</span><span class='line'>
</span><span class='line'> if (fileStatus.isDirectory()) {
</span><span class='line'>   FileStatus[] allStatus = fs.listStatus(path);
</span><span class='line'>   for (FileStatus status : allStatus) {
</span><span class='line'>     DistributedCache.addCacheFile(status.getPath().toUri(), conf);
</span><span class='line'>     LOG.info("add file : " + status.getPath().toString());
</span><span class='line'>   }
</span><span class='line'> } else {
</span><span class='line'>   DistributedCache.addCacheFile(path.toUri(), conf);
</span><span class='line'>   LOG.info("add file: " + path.toString());
</span><span class='line'> }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<ol>
<li><p>DistributedCache 无法使用：可能的原因是使用的conf是在new Job</p></li>
<li><p>如果distributed cache使用了很多的文件都是part-r-00000这样的文件，可以使用alias这样的办法处理:</p></li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>job.addCacheFile(new URI(options.getIdf() + "#" + IDF_ALIAS));</span></code></pre></td></tr></table></div></figure>


<h3>3. 关于Lzo和Lzop</h3>

<ol>
<li>使用lzo压缩格式压缩文件</li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>OutputFormat.setCompressOutput(job, true);
</span><span class='line'>OutputFormat.setOutputCompressor( job, LzopCodec.class)</span></code></pre></td></tr></table></div></figure>


<ol>
<li>LzoCodec 和 LzopCodec的区别</li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>lzo 是一个压缩的lib，可以用来快速的压缩和解压缩，用来map和reduce中间
</span><span class='line'>lzop是一个文件压缩的方式，和gzip相同，用来输出</span></code></pre></td></tr></table></div></figure>


<h3>4. 关于shuffle error</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>job 出现了 org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#3, 
</span><span class='line'>网上有很多调整内存的方法，好像都没用。试了一会，调整reduce的内存，还是没用。最后，调整了reducer 的个数，job跑过。</span></code></pre></td></tr></table></div></figure>

</div>


<!-- 多说评论框 start -->
<div class="ds-thread" data-thread-key="/blog/2016/06/08/hadoopbi-ji" data-title="Hadoop笔记" data-url="http://bigbear2017.github.io/blog/2016/06/08/hadoopbi-ji/"></div>
<!-- 多说评论框 end -->
<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
<script type="text/javascript">
    var duoshuoQuery = {short_name:"bigbear2017"};
    (function() {

        var ds = document.createElement('script');
        ds.type = 'text/javascript';ds.async = true;
        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
        ds.charset = 'UTF-8';
        (document.getElementsByTagName('head')[0]
         || document.getElementsByTagName('body')[0]).appendChild(ds);
     })();
 </script>
 <!-- 多说公共JS代码 end -->


<div class="sharing">
  
  
  
</div>
</article>
</div>
	<footer id="footer" class="inner"><script type="text/x-mathjax-config"> 
MathJax.Hub.Config({
	tex2jax: {
		inlineMath: [ ['$','$'] ],
		displayMath: [ ['$$','$$'] ],
	},
	processEscapes: true
});
</script>
<!--script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"--><!--/script-->
<script type="text/javascript" src="http://www.bigbear2017.com/mathjax/MathJax.js?config=default"></script>
<div class="aboutme">
<hr>
  <div class="profile">
    <a href="http://twitter.com/"><img class="icon" src=""></a>

    <h3>Cao Nannan</h3>
    <p><a href="http://twitter.com/">@</a></p>

    <div class="codes">
      <h4>Codes</h4>
      <div class="github"><a href="https://github.com/bigbear2017">github.com/bigbear2017</a></div>
    </div>
  </div>

  <div class="float_clear"></div>

</div>

Copyright &copy; 2016
 Cao Nannan 
<br>
Powered by Octopress.



</footer>
	

</body>
</html>
